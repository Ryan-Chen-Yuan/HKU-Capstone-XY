#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿ƒç†å’¨è¯¢å¯¹è¯ç³»ç»Ÿæ ¸å¿ƒé€»è¾‘å®ç°ï¼ˆé›†æˆç‰ˆï¼‰

è¯¥ç‰ˆæœ¬ä½¿ç”¨ç»Ÿä¸€çš„Databaseç±»æ¥ç®¡ç†æ‰€æœ‰æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
1. ä¼šè¯çŠ¶æ€ç®¡ç†
2. ç”¨æˆ·ç”»åƒå­˜å‚¨
3. é•¿çŸ­æœŸè®°å¿†ç®¡ç†
4. æƒ…ç»ªè¯„åˆ†è®°å½•
5. è¡Œä¸ºæ¨¡å¼åˆ†æ
6. å¯¹è¯è®¡åˆ’ç®¡ç†

ä¼˜åŠ¿ï¼š
- ç»Ÿä¸€çš„æ•°æ®ç®¡ç†æ¥å£
- çº¿ç¨‹å®‰å…¨çš„æ•°æ®è®¿é—®
- æ›´å¥½çš„æ•°æ®ä¸€è‡´æ€§
- ç®€åŒ–çš„é”™è¯¯å¤„ç†
"""
import os
import json
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))
from datetime import datetime
from typing import Dict, List, Tuple, Any
import re
import requests
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from pydantic import BaseModel, Field
from snownlp import SnowNLP

from utils.extract_json import extract_json
from dao.database import Database

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä¼šè¯çŠ¶æ€æ•°æ®æ¨¡å‹
class SessionState(BaseModel):
    user_input: str
    response: str | None = None
    user_id: str = "default_user"
    history: List[Dict[str, str]] = Field(default_factory=list)
    session_id: str | None = None
    user_profile: Dict[str, Any] = Field(default_factory=dict)
    crisis_detected: bool = False
    crisis_reason: str | None = None
    search_results: str | None = None
    plan: Dict[str, Any] = Field(default_factory=dict)
    pattern_analysis: Dict[str, Any] | None = None
    inquiry_result: Dict[str, Any] | None = None

# å±æœºæ£€æµ‹ç±»
class CrisisDetector:
    _KEYWORDS = {"è‡ªæ€", "æƒ³æ­»", "æ´»ä¸ä¸‹å»", "ç»“æŸç”Ÿå‘½", "æ€äºº", "ä¼¤å®³è‡ªå·±", "å—ä¸äº†", "ç»æœ›", "å´©æºƒ"}
    _THRESH = -0.3

    def check(self, text: str) -> Tuple[bool, str | None]:
        for kw in self._KEYWORDS:
            if kw in text:
                return True, f"æ£€æµ‹åˆ°é«˜å±è¯: '{kw}'"
        polarity = SnowNLP(text).sentiments * 2 - 1
        if polarity <= self._THRESH:
            return True, f"æƒ…æ„Ÿææ€§è¿‡ä½ (polarity={polarity:.2f})"
        return False, None

# é›†æˆç‰ˆèŠå¤©æœåŠ¡æ ¸å¿ƒç±»
class ChatService:
    def __init__(self, database: Database):
        self.db = database  # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®åº“å®ä¾‹
        self.model = os.environ.get("MODEL_NAME", "deepseek-chat")
        self.client = ChatOpenAI(
            model=self.model,
            api_key=os.environ.get("OPENAI_API_KEY"),
            base_url=os.environ.get("BASE_URL", "https://api.deepseek.com/v1"),
            temperature=float(os.environ.get("TEMPERATURE", "0.7")),
            max_tokens=int(os.environ.get("MAX_TOKENS", "1000")),
            timeout=40,
        )
        
        self.enable_guided_inquiry = os.environ.get("ENABLE_GUIDED_INQUIRY", "true").lower() == "true"
        self.enable_pattern_analysis = os.environ.get("ENABLE_PATTERN_ANALYSIS", "true").lower() == "true"
        
        self.prompt_template = self._load_prompt_template()
        self.planning_prompt = self._load_planning_prompt()
        self.guided_inquiry_prompt = self._load_guided_inquiry_prompt()
        self.pattern_analysis_prompt = self._load_pattern_analysis_prompt()

    def _load_prompt_template(self):
        prompt_dir = os.path.join(os.path.dirname(__file__), "../prompt")
        os.makedirs(prompt_dir, exist_ok=True)
        prompt_file = os.path.join(prompt_dir, "counselor_prompt.txt")

        if not os.path.exists(prompt_file):
            default_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å’¨è¯¢å¸ˆï¼Œåå«"çŸ¥å·±å’¨è¯¢å¸ˆ"ã€‚ä½ çš„ç›®æ ‡æ˜¯é€šè¿‡å¯¹è¯å¸®åŠ©ç”¨æˆ·è§£å†³å¿ƒç†å›°æ‰°ã€æƒ…ç»ªé—®é¢˜ï¼Œå¹¶æä¾›ä¸“ä¸šçš„å¿ƒç†æ”¯æŒã€‚

è¯·æ³¨æ„ä»¥ä¸‹æŒ‡å¯¼åŸåˆ™ï¼š
1. ä¿æŒå…±æƒ…ã€å°Šé‡å’Œæ”¯æŒçš„æ€åº¦
2. æä¾›å¾ªè¯çš„å¿ƒç†å­¦å»ºè®®
3. ä¸è¦ç»™å‡ºåŒ»ç–—è¯Šæ–­æˆ–å¤„æ–¹
4. å½“ç”¨æˆ·éœ€è¦ä¸“ä¸šåŒ»ç–—å¸®åŠ©æ—¶ï¼Œå»ºè®®ä»–ä»¬å¯»æ±‚ä¸“ä¸šåŒ»ç”Ÿçš„å¸®åŠ©
5. å›å¤è¦ç®€æ´ã€æ¸…æ™°ï¼Œæ˜“äºç”¨æˆ·ç†è§£
6. é€‚å½“ä½¿ç”¨å¼€æ”¾å¼é—®é¢˜é¼“åŠ±ç”¨æˆ·è¡¨è¾¾

ç¤ºä¾‹å›å¤æ ¼å¼ï¼š
"æˆ‘ç†è§£ä½ ç°åœ¨çš„æ„Ÿå—ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å°è¯•...
å¸Œæœ›è¿™äº›å»ºè®®å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼"
"""
            with open(prompt_file, "w", encoding="utf-8") as f:
                f.write(default_prompt)
            return default_prompt

        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read()

    def _load_planning_prompt(self):
        prompt_dir = os.path.join(os.path.dirname(__file__), "../prompt")
        prompt_file = os.path.join(prompt_dir, "planning_prompt.txt")
        if not os.path.exists(prompt_file):
            raise FileNotFoundError("Planning prompt file not found")
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read()

    def _load_guided_inquiry_prompt(self):
        prompt_dir = os.path.join(os.path.dirname(__file__), "../prompt")
        prompt_file = os.path.join(prompt_dir, "guided_inquiry_prompt.txt")
        if not os.path.exists(prompt_file):
            raise FileNotFoundError("Guided inquiry prompt file not found")
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read()

    def _load_pattern_analysis_prompt(self):
        prompt_dir = os.path.join(os.path.dirname(__file__), "../prompt")
        prompt_file = os.path.join(prompt_dir, "pattern_analysis_prompt.txt")
        if not os.path.exists(prompt_file):
            raise FileNotFoundError("Pattern analysis prompt file not found")
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read()

    def save_memory(self, user_id: str, content: str, is_long_term: bool = False):
        """ä¿å­˜è®°å¿†åˆ°æ•°æ®åº“"""
        if is_long_term:
            self.db.save_long_term_memory(user_id, content)
        # çŸ­æœŸè®°å¿†å¯ä»¥é€šè¿‡å…¶ä»–æ–¹å¼ç®¡ç†ï¼Œæˆ–è€…æ‰©å±•Databaseç±»æ”¯æŒ

    def get_memory_context(self, user_id: str, k: int = 5) -> str:
        """è·å–è®°å¿†ä¸Šä¸‹æ–‡"""
        long_term_memories = self.db.get_long_term_memory(user_id, k)
        return "\n".join(f"{m['time']}: {m['content']}" for m in long_term_memories)

    def update_user_profile(self, user_id: str, profile_data: Dict[str, Any]):
        """æ›´æ–°ç”¨æˆ·ç”»åƒ"""
        self.db.save_user_profile(user_id, profile_data)

    def get_user_profile(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·ç”»åƒ"""
        return self.db.get_user_profile(user_id)

    def save_emotion_score(self, user_id: str, session_id: str, emotion_score: float, emotion_category: str = None):
        """ä¿å­˜æƒ…ç»ªè¯„åˆ†"""
        self.db.save_emotion_score(user_id, session_id, emotion_score, emotion_category)

    def _update_plan(self, session_id: str, message: str, history: List[Dict[str, str]]):
        """æ›´æ–°å¯¹è¯è®¡åˆ’"""
        plan = self.db.get_session_plan(session_id)
        if not plan:
            plan = {
                "session_id": session_id,
                "user_intent": {
                    "type": "unknown",
                    "description": "",
                    "confidence": 0.0,
                    "identified_at": datetime.now().isoformat(),
                },
                "current_state": {
                    "stage": "intent_identification",
                    "progress": 0.0,
                    "last_updated": datetime.now().isoformat(),
                },
                "steps": [],
                "context": {"key_points": [], "emotions": [], "concerns": []},
                "inquiry_status": {
                    "stage": "åˆå§‹é˜¶æ®µ",
                    "information_completeness": 0,
                    "collected_info": {},
                    "pattern_analyzed": False
                }
            }

        messages = [
            {"role": "system", "content": self.planning_prompt},
            {
                "role": "user",
                "content": f"Current plan: {json.dumps(plan, ensure_ascii=False)}\n\nCurrent message: {message}\n\nHistory: {json.dumps(history, ensure_ascii=False)}",
            },
        ]

        response = self.client.invoke(messages)
        reply = response.content.strip()

        try:
            updated_plan = extract_json(reply)
            if updated_plan is None:
                plan["current_state"]["last_updated"] = datetime.now().isoformat()
                return plan

            if "inquiry_status" not in updated_plan:
                updated_plan["inquiry_status"] = plan.get("inquiry_status", {
                    "stage": "åˆå§‹é˜¶æ®µ",
                    "information_completeness": 0,
                    "collected_info": {},
                    "pattern_analyzed": False
                })

            self.db.save_session_plan(session_id, updated_plan)
            return updated_plan
        except Exception as e:
            print(f"Error updating plan: {str(e)}")
            return plan

    def _analyze_behavior_pattern(self, session_id: str, collected_info: Dict[str, Any]):
        """åˆ†æè¡Œä¸ºæ¨¡å¼"""
        try:
            messages = [
                {"role": "system", "content": self.pattern_analysis_prompt},
                {
                    "role": "user",
                    "content": f"è¯·åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„ä¿¡æ¯åˆ†æå®¢æˆ·çš„è¡Œä¸ºæ¨¡å¼ï¼š\n\n{json.dumps(collected_info, ensure_ascii=False)}"
                }
            ]

            response = self.client.invoke(messages)
            reply = response.content.strip()
            
            pattern_analysis = extract_json(reply)
            if pattern_analysis is None:
                return None

            pattern_analysis["analyzed_at"] = datetime.now().isoformat()
            pattern_analysis["session_id"] = session_id
            self.db.save_pattern_analysis(session_id, pattern_analysis)
            return pattern_analysis
        except Exception as e:
            print(f"Error analyzing behavior pattern: {str(e)}")
            return None

    def _format_history(self, history: List[Dict[str, str]]):
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        formatted_messages = []
        formatted_messages.append({"role": "system", "content": self.prompt_template})

        for msg in history:
            if msg["role"] == "user":
                formatted_messages.append({"role": "user", "content": msg["content"]})
            elif msg["role"] == "agent":
                formatted_messages.append({"role": "assistant", "content": msg["content"]})

        return formatted_messages

    def _extract_emotion(self, content: str):
        """æå–æƒ…ç»ªä¿¡æ¯"""
        emotion_match = re.search(r"#(happy|sad|angry|sleepy|neutral)\b", content, re.IGNORECASE)

        if emotion_match:
            emotion = emotion_match.group(1).lower()
            clean_content = re.sub(r"\s*#(happy|sad|angry|sleepy|neutral)\b", "", content, flags=re.IGNORECASE)
            return clean_content, emotion

        content_lower = content.lower()

        if any(word in content_lower for word in ["å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "å¾ˆå¥½", "å¾ˆæ£’", "å…´å¥‹"]):
            return content, "happy"
        elif any(word in content_lower for word in ["æ‚²ä¼¤", "éš¾è¿‡", "ä¼¤å¿ƒ", "ç—›è‹¦", "æŠ‘éƒ"]):
            return content, "sad"
        elif any(word in content_lower for word in ["ç”Ÿæ°”", "æ„¤æ€’", "æ¼ç«", "çƒ¦èº", "çƒ¦æ¼"]):
            return content, "angry"
        elif any(word in content_lower for word in ["ç´¯äº†", "ç–²æƒ«", "å›°", "ç¡è§‰", "ä¼‘æ¯"]):
            return content, "sleepy"

        return content, "neutral"

    def get_response(self, message: str, history: List[Dict[str, str]] = None, session_id: str = None) -> Dict[str, Any]:
        """è·å–AIå›å¤ï¼ˆé›†æˆç‰ˆï¼‰"""
        try:
            user_id = "default_user"  # å¯ä»¥æ ¹æ®éœ€è¦åŠ¨æ€è®¾ç½®
            
            # è°ƒç”¨chatå‡½æ•°è·å–å®Œæ•´å“åº”
            result = chat(message, user_id=user_id, session_id=session_id, history=history or [])
            
            # æå–å¹¶æ ¼å¼åŒ–å“åº”å†…å®¹
            response_content = result.get("response", "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å›ç­”ã€‚")
            
            # æå–æƒ…ç»ªä¿¡æ¯
            clean_content, emotion = self._extract_emotion(response_content)
            
            return {
                "content": clean_content,
                "emotion": emotion,
                "crisis_detected": result.get("crisis_detected", False),
                "crisis_reason": result.get("crisis_reason"),
                "search_results": result.get("search_results"),
                "pattern_analysis": result.get("pattern_analysis")
            }
            
        except Exception as e:
            print(f"Error in get_response: {str(e)}")
            return {
                "content": f"å¯¹è¯å¤„ç†å‡ºé”™: {str(e)}",
                "emotion": "neutral",
                "crisis_detected": False
            }

# åˆå§‹åŒ–æœåŠ¡å’Œå­˜å‚¨
db = Database()
crisis_detector = CrisisDetector()
chat_service = ChatService(db)

# æœç´¢åŠŸèƒ½
SERPAPI_KEY = os.getenv("SERPAPI_KEY")
SEARCH_TRIGGERS = [
    "ä»€ä¹ˆæ˜¯", "å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆåŠ", "æœ€æ–°", "ç°åœ¨", "ä»Šå¤©", "æ–°é—»", "å¤©æ°”",
    "å‘Šè¯‰æˆ‘", "ä»‹ç»", "è¯´è¯´", "è®²è®²", "äº†è§£", "å…³äº", "æ´»åŠ¨", "äº‹ä»¶", "æƒ…å†µ"
]

def serp_search(query: str, k: int = 3) -> str:
    """ç½‘ç»œæœç´¢åŠŸèƒ½"""
    if not SERPAPI_KEY:
        return "âš ï¸ [æœç´¢åŠŸèƒ½æœªå¯ç”¨: æœªè®¾ç½® SERPAPI_KEY]"
    try:
        r = requests.get(
            "https://serpapi.com/search",
            params={"q": query, "api_key": SERPAPI_KEY, "hl": "zh-cn"},
            timeout=15,
        )
        r.raise_for_status()
        data = r.json()
        snippets: List[str] = []
        for item in data.get("organic_results", [])[:k]:
            snippets.append(
                f"æ ‡é¢˜: {item.get('title','').strip()}\næ‘˜è¦: {item.get('snippet','').strip()}\né“¾æ¥: {item.get('link','').strip()}"
            )
        return "\n\n".join(snippets) if snippets else "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"
    except Exception as e:
        return f"æœç´¢å‡ºé”™: {e}"

def process_input(state: SessionState) -> SessionState:
    """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆé›†æˆç‰ˆï¼‰"""
    uid, raw = state.user_id, state.user_input.strip()
    session_id = state.session_id or uid
    state.session_id = session_id

    # å±æœºæ£€æµ‹
    crisis, reason = crisis_detector.check(raw)
    if crisis:
        state.response = (
            f"âš ï¸ æ£€æµ‹åˆ°æ½œåœ¨æƒ…ç»ªå±æœº: {reason}\n\n"
            "è¯·ç«‹å³è”ç³»ä¸“ä¸šäººå£«æˆ–æ‹¨æ‰“å¿ƒç†æ´åŠ©çƒ­çº¿ 400-161-9995ã€‚\n"
            "æ‚¨å¹¶ä¸å­¤å•ï¼Œæˆ‘ä»¬å…³å¿ƒæ‚¨ã€‚"
        )
        state.crisis_detected = True
        state.crisis_reason = reason
        # ä¿å­˜å±æœºè®°å½•åˆ°é•¿æœŸè®°å¿†
        chat_service.save_memory(uid, f"[CRISIS] {raw} â€“ {reason}", is_long_term=True)
        return state

    # æ„å»ºä¸Šä¸‹æ–‡
    profile = chat_service.get_user_profile(uid)
    mem_ctx = chat_service.get_memory_context(uid)
    search_out = serp_search(raw) if any(t in raw for t in SEARCH_TRIGGERS) else None
    state.search_results = search_out

    # æ›´æ–°å¯¹è¯è®¡åˆ’
    plan = chat_service._update_plan(session_id, raw, state.history)
    state.plan = plan

    # æ ¼å¼åŒ–å†å²è®°å½•
    messages = chat_service._format_history(state.history)
    messages.append({"role": "user", "content": raw})

    # å‡†å¤‡ç³»ç»Ÿæç¤ºçš„é™„åŠ ä¿¡æ¯
    additional_context = f"\n\nå½“å‰å¯¹è¯è®¡åˆ’ï¼š{json.dumps(plan, ensure_ascii=False)}"
    
    if search_out:
        additional_context += f"\n\nç›¸å…³æœç´¢ä¿¡æ¯ï¼š{search_out}"

    messages[0]["content"] += additional_context

    # è°ƒç”¨LLM
    try:
        ai_msg = chat_service.client.invoke(messages)
        reply = ai_msg.content.strip() or "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å›ç­”ã€‚"
    except Exception as e:
        reply = f"å¯¹è¯å¤„ç†å‡ºé”™: {e}"

    # æå–æƒ…ç»ª
    clean_content, emotion = chat_service._extract_emotion(reply)
    state.response = clean_content

    # ä¿å­˜è®°å¿†ï¼ˆæ¯3æ¬¡å¯¹è¯ä¿å­˜ä¸€æ¬¡åˆ°é•¿æœŸè®°å¿†ï¼‰
    emotion_history = db.get_emotion_history(uid)
    is_long_term = (len(emotion_history) + 1) % 3 == 0
    chat_service.save_memory(uid, f"ç”¨æˆ·: {raw}\nå’¨è¯¢å¸ˆ: {reply}", is_long_term=is_long_term)

    # æ›´æ–°ç”¨æˆ·ç”»åƒå’Œæƒ…ç»ªè¯„åˆ†
    emotion_score = SnowNLP(raw).sentiments * 2 - 1
    chat_service.update_user_profile(uid, {
        "last_interaction": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "recent_emotion_score": emotion_score
    })
    chat_service.save_emotion_score(uid, session_id, emotion_score, emotion)
    
    state.user_profile = chat_service.get_user_profile(uid)

    # æ›´æ–°å†å²è®°å½•
    state.history.append({"role": "user", "content": raw})
    state.history.append({"role": "agent", "content": clean_content})

    return state

# æ„å»ºLangGraph
workflow = StateGraph(SessionState)
workflow.add_node("process_input", process_input)
workflow.set_entry_point("process_input")
workflow.add_edge("process_input", END)

# ç¼–è¯‘åº”ç”¨
chat_app = workflow.compile()

def chat(user_input: str, user_id: str = "default_user", session_id: str | None = None, history: List[Dict[str, str]] | None = None) -> Dict[str, Any]:
    """èŠå¤©æ¥å£å‡½æ•°ï¼ˆé›†æˆç‰ˆï¼‰"""
    init_state = SessionState(
        user_input=user_input,
        user_id=user_id,
        session_id=session_id,
        history=history or []
    )
    result = chat_app.invoke(init_state)
    final_state = result if isinstance(result, dict) else result
    
    return {
        "response": final_state.get("response"),
        "history": final_state.get("history", []),
        "crisis_detected": final_state.get("crisis_detected", False),
        "crisis_reason": final_state.get("crisis_reason"),
        "search_results": final_state.get("search_results"),
        "pattern_analysis": final_state.get("pattern_analysis")
    }

if __name__ == "__main__":
    print("ğŸ©º å¿ƒç†å’¨è¯¢å¯¹è¯ç³»ç»Ÿ (é›†æˆç‰ˆ) (è¾“å…¥ 'é€€å‡º' ç»“æŸ)")
    history = []
    while True:
        try:
            u_in = input("æ‚¨: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ å†è§ï¼")
            break
        if u_in.lower() in {"é€€å‡º", "quit", "q"}:
            print("ğŸ‘‹ å†è§ï¼ç¥æ‚¨ä¸€åˆ‡é¡ºåˆ©ã€‚")
            break
        result = chat(u_in, history=history)
        print(f"å’¨è¯¢å¸ˆ: {result['response']}")
        history = result['history']
