#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿ƒç†å’¨è¯¢å¯¹è¯ç³»ç»Ÿæ ¸å¿ƒé€»è¾‘å®ç°

è¯¥æ–‡ä»¶å®ç°äº†ä¸€ä¸ªåŸºäºAIçš„å¿ƒç†å’¨è¯¢å¯¹è¯æœåŠ¡ï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä¼šè¯çŠ¶æ€ç®¡ç† - è·Ÿè¸ªç”¨æˆ·è¾“å…¥ã€å†å²å¯¹è¯ã€å±æœºæ£€æµ‹çŠ¶æ€ç­‰
2. ç”¨æˆ·ç”»åƒå­˜å‚¨ - æŒä¹…åŒ–ä¿å­˜ç”¨æˆ·ç›¸å…³ä¿¡æ¯
3. è®°å¿†ç®¡ç† - ç»´æŠ¤é•¿çŸ­æœŸå¯¹è¯è®°å¿†
4. å±æœºæ£€æµ‹ - é€šè¿‡å…³é”®è¯åŒ¹é…å’Œæƒ…æ„Ÿåˆ†æè¯†åˆ«æ½œåœ¨è‡ªæ€é£é™©
5. èŠå¤©æœåŠ¡ - å¤„ç†å¯¹è¯é€»è¾‘ã€è°ƒç”¨LLMæ¨¡å‹ç”Ÿæˆå›å¤
6. è¡Œä¸ºæ¨¡å¼åˆ†æ - åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼å¹¶æä¾›å’¨è¯¢å»ºè®®
7. å¼•å¯¼å¼è¯¢é—® - è¯„ä¼°ä¿¡æ¯å®Œæ•´æ€§å¹¶ç”Ÿæˆè¿½é—®é—®é¢˜

æŠ€æœ¯æ ˆï¼š
- Python 3.8+
- LangChain - LLMäº¤äº’å’Œå·¥ä½œæµç®¡ç†
- Pydantic - æ•°æ®æ¨¡å‹éªŒè¯
- SnowNLP - ä¸­æ–‡æƒ…æ„Ÿåˆ†æ
- LangGraph - å¯¹è¯æµç¨‹ç®¡ç†
"""
import os
import json
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))
from datetime import datetime
from typing import Dict, List, Tuple, Any
import re
import requests
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from pydantic import BaseModel, Field
from snownlp import SnowNLP

from utils.extract_json import extract_json

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä¼šè¯çŠ¶æ€æ•°æ®æ¨¡å‹
class SessionState(BaseModel):
    """
    è·Ÿè¸ªå•æ¬¡å¯¹è¯ä¼šè¯ä¸­çš„æ‰€æœ‰çŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç”¨æˆ·è¾“å…¥ã€å†å²å¯¹è¯ã€
    å±æœºæ£€æµ‹ç»“æœã€æœç´¢ç»“æœç­‰å…³é”®æ•°æ®
    """
    user_input: str  # ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬å†…å®¹
    response: str | None = None  # ç³»ç»Ÿç”Ÿæˆçš„å›å¤å†…å®¹
    user_id: str = "default_user"  # ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œé»˜è®¤ä¸º"default_user"
    history: List[Dict[str, str]] = Field(default_factory=list)  # å¯¹è¯å†å²è®°å½•ï¼ŒåŒ…å«ç”¨æˆ·å’Œç³»ç»Ÿçš„æ¶ˆæ¯
    session_id: str | None = None  # ä¼šè¯IDï¼Œç”¨äºæ ‡è¯†ä¸åŒçš„å¯¹è¯ä¼šè¯
    user_profile: Dict[str, Any] = Field(default_factory=dict)  # ç”¨æˆ·ç”»åƒæ•°æ®ï¼ŒåŒ…å«ç”¨æˆ·ç›¸å…³ä¿¡æ¯
    crisis_detected: bool = False  # æ˜¯å¦æ£€æµ‹åˆ°å±æœºæƒ…å†µ
    crisis_reason: str | None = None  # å±æœºæ£€æµ‹çš„åŸå› è¯´æ˜
    search_results: str | None = None  # æœç´¢ç»“æœå†…å®¹
    plan: Dict[str, Any] = Field(default_factory=dict)  # å¯¹è¯è®¡åˆ’ï¼ŒåŒ…å«å½“å‰é˜¶æ®µå’Œè¿›åº¦ç­‰ä¿¡æ¯
    pattern_analysis: Dict[str, Any] | None = None  # è¡Œä¸ºæ¨¡å¼åˆ†æç»“æœ
    inquiry_result: Dict[str, Any] | None = None  # å¼•å¯¼æ€§è¯¢é—®è¯„ä¼°ç»“æœ

# ç”¨æˆ·ç”»åƒå­˜å‚¨ç®¡ç†ç±»
class UserProfileStore:
    """
    è´Ÿè´£æŒä¹…åŒ–å­˜å‚¨å’Œç®¡ç†ç”¨æˆ·ç”»åƒæ•°æ®ï¼ŒåŒ…æ‹¬æœ€åäº¤äº’æ—¶é—´ã€æƒ…ç»ªè¯„åˆ†ç­‰
    æ•°æ®å­˜å‚¨åœ¨JSONæ–‡ä»¶ä¸­ï¼Œæ”¯æŒç”¨æˆ·ç”»åƒçš„è·å–å’Œæ›´æ–°æ“ä½œ
    """
    _PATH = os.path.join(os.path.dirname(__file__), "../data/user_profiles.json")
   # åˆå§‹åŒ–ç”¨æˆ·ç”»åƒå­˜å‚¨ç³»ç»Ÿ
    def __init__(self):
        self._profiles: Dict[str, Dict[str, Any]] = {}
        os.makedirs(os.path.dirname(self._PATH), exist_ok=True)
        if os.path.exists(self._PATH):
            # å°è¯•ä»JSONæ–‡ä»¶åŠ è½½å·²æœ‰ç”¨æˆ·ç”»åƒ
            try:
                with open(self._PATH, "r", encoding="utf-8") as fp:
                    self._profiles = json.load(fp)
            except Exception:
                self._profiles = {}
    # è·å–æŒ‡å®šç”¨æˆ·çš„ç”»åƒæ•°æ®
    def get(self, uid: str) -> Dict[str, Any]:
        return self._profiles.get(uid, {})
    # æ›´æ–°æˆ–æ’å…¥ç”¨æˆ·ç”»åƒæ•°æ®
    def upsert(self, uid: str, data: Dict[str, Any]):
        self._profiles.setdefault(uid, {}).update(data)
        try:
            with open(self._PATH, "w", encoding="utf-8") as fp:
                json.dump(self._profiles, fp, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç”¨æˆ·ç”»åƒå¤±è´¥: {e}")

# å¯¹è¯è®°å¿†å­˜å‚¨ç®¡ç†ç±»
class MemoryStore:
    """
    ç»´æŠ¤ç”¨æˆ·çš„é•¿çŸ­æœŸå¯¹è¯è®°å¿†ï¼Œé•¿æœŸè®°å¿†æŒä¹…åŒ–å­˜å‚¨åœ¨JSONæ–‡ä»¶ä¸­ï¼Œ
    çŸ­æœŸè®°å¿†ä¿å­˜åœ¨å†…å­˜ä¸­å¹¶é™åˆ¶é•¿åº¦ã€‚æä¾›è®°å¿†ä¸Šä¸‹æ–‡æ„å»ºåŠŸèƒ½ã€‚
    """
    _PATH = os.path.join(os.path.dirname(__file__), "../data/long_term_memory.json")

    def __init__(self):
        # é•¿æœŸè®°å¿†
        self._long: Dict[str, List[Dict[str, str]]] = {}
        # çŸ­æœŸè®°å¿†
        self._short: Dict[str, List[Dict[str, str]]] = {}
        os.makedirs(os.path.dirname(self._PATH), exist_ok=True)
        if os.path.exists(self._PATH):
            try:
                with open(self._PATH, "r", encoding="utf-8") as fp:
                    self._long = json.load(fp)
            except Exception:
                self._long = {}

    # ä¸ºå†…å®¹æ·»åŠ æ—¶é—´æˆ³
    @staticmethod
    def _stamp(content: str) -> Dict[str, str]:
        return {"time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "content": content}

    # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œç»„åˆæœ€è¿‘kæ¡é•¿æœŸè®°å¿†ä¸å…¨éƒ¨çŸ­æœŸè®°å¿†
    def context(self, uid: str, k: int = 5) -> str:
        ctx = self._long.get(uid, [])[-k:] + self._short.get(uid, [])
        return "\n".join(f"{c['time']}: {c['content']}" for c in ctx)

    # æ·»åŠ å†…å®¹åˆ°è®°å¿†ç³»ç»Ÿ
    def add(self, uid: str, content: str, *, long_term: bool = False):
        # é•¿æœŸè®°å¿†
        if long_term:
            self._long.setdefault(uid, []).append(self._stamp(content))
            try:
                with open(self._PATH, "w", encoding="utf-8") as fp:
                    json.dump(self._long, fp, indent=2, ensure_ascii=False)
            except Exception:
                pass
        # çŸ­æœŸè®°å¿†
        else:
            self._short.setdefault(uid, []).append(self._stamp(content))
            if len(self._short[uid]) > 20:
                self._short[uid].pop(0)

# å±æœºæ£€æµ‹ç±»
class CrisisDetector:
    """
    é€šè¿‡å…³é”®è¯åŒ¹é…å’Œæƒ…æ„Ÿåˆ†æè¯†åˆ«ç”¨æˆ·æ½œåœ¨çš„è‡ªæ€æˆ–è‡ªä¼¤é£é™©ã€‚
    ä½¿ç”¨SnowNLPè¿›è¡Œæƒ…æ„Ÿææ€§åˆ†æï¼Œç»“åˆé«˜å±å…³é”®è¯åˆ—è¡¨è¿›è¡Œå±æœºåˆ¤æ–­ã€‚
    """
    _KEYWORDS = {"è‡ªæ€", "æƒ³æ­»", "æ´»ä¸ä¸‹å»", "ç»“æŸç”Ÿå‘½", "æ€äºº", "ä¼¤å®³è‡ªå·±", "å—ä¸äº†", "ç»æœ›", "å´©æºƒ"}
    _THRESH = -0.8  # è°ƒæ•´é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦æ•æ„Ÿ

    def check(self, text: str) -> Tuple[bool, str | None]:
        # å…ˆæ£€æŸ¥å…³é”®è¯
        for kw in self._KEYWORDS:
            if kw in text:
                return True, f"æ£€æµ‹åˆ°é«˜å±è¯: '{kw}'"
        
        # åªæœ‰åœ¨åŒ…å«æƒ…ç»ªç›¸å…³è¯æ±‡æ—¶æ‰è¿›è¡Œæƒ…æ„Ÿåˆ†æ
        emotion_indicators = ["æ„Ÿåˆ°", "è§‰å¾—", "å¾ˆ", "éå¸¸", "ç‰¹åˆ«", "å¿ƒæƒ…", "æƒ…ç»ª", "éš¾å—", "ç—›è‹¦", "æ— åŠ©"]
        if any(indicator in text for indicator in emotion_indicators):
            polarity = SnowNLP(text).sentiments * 2 - 1
            if polarity <= self._THRESH:
                return True, f"æƒ…æ„Ÿææ€§è¿‡ä½ (polarity={polarity:.2f})"
        
        return False, None

# èŠå¤©æœåŠ¡æ ¸å¿ƒç±»
class ChatService:
    """
    å®ç°å¿ƒç†å’¨è¯¢å¯¹è¯çš„æ ¸å¿ƒé€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
    - åŠ è½½å’Œç®¡ç†å„ç±»æç¤ºæ¨¡æ¿
    - è°ƒç”¨LLMæ¨¡å‹ç”Ÿæˆå›å¤
    - è¯„ä¼°ä¿¡æ¯å®Œæ•´æ€§å¹¶ç”Ÿæˆå¼•å¯¼æ€§é—®é¢˜
    - åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼
    - ç®¡ç†å¯¹è¯è®¡åˆ’å’Œä¸Šä¸‹æ–‡
    """
    def __init__(self):
        self.model = os.environ.get("MODEL_NAME", "deepseek-chat")
        self.client = ChatOpenAI(
            model=self.model,
            api_key=os.environ.get("OPENAI_API_KEY"),
            base_url=os.environ.get("BASE_URL", "https://api.deepseek.com/v1"),
            temperature=float(os.environ.get("TEMPERATURE", "0.7")),
            max_tokens=int(os.environ.get("MAX_TOKENS", "1000")),
            timeout=40,
        )
        
        self.enable_guided_inquiry = os.environ.get("ENABLE_GUIDED_INQUIRY", "true").lower() == "true"
        self.enable_pattern_analysis = os.environ.get("ENABLE_PATTERN_ANALYSIS", "true").lower() == "true"
        
        self.prompt_template = self._load_prompt_template()
        self.planning_prompt = self._load_planning_prompt()
        self.guided_inquiry_prompt = self._load_guided_inquiry_prompt()
        self.pattern_analysis_prompt = self._load_pattern_analysis_prompt()
        
        self.plans_dir = os.path.join(os.path.dirname(__file__), "../data/plans")
        self.patterns_dir = os.path.join(os.path.dirname(__file__), "../data/patterns")
        os.makedirs(self.plans_dir, exist_ok=True)
        os.makedirs(self.patterns_dir, exist_ok=True)

    # åŠ è½½å¿ƒç†å’¨è¯¢å¸ˆæç¤ºæ¨¡æ¿
    def _load_prompt_template(self):
        prompt_dir = os.path.join(os.path.dirname(__file__), "../prompt")
        os.makedirs(prompt_dir, exist_ok=True)
        prompt_file = os.path.join(prompt_dir, "counselor_prompt.txt")

        if not os.path.exists(prompt_file):
            default_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å’¨è¯¢å¸ˆï¼Œåå«"çŸ¥å·±å’¨è¯¢å¸ˆ"ã€‚ä½ çš„ç›®æ ‡æ˜¯é€šè¿‡å¯¹è¯å¸®åŠ©ç”¨æˆ·è§£å†³å¿ƒç†å›°æ‰°ã€æƒ…ç»ªé—®é¢˜ï¼Œå¹¶æä¾›ä¸“ä¸šçš„å¿ƒç†æ”¯æŒã€‚
            è¯·æ³¨æ„ä»¥ä¸‹æŒ‡å¯¼åŸåˆ™ï¼š
            1. ä¿æŒå…±æƒ…ã€å°Šé‡å’Œæ”¯æŒçš„æ€åº¦
            2. æä¾›å¾ªè¯çš„å¿ƒç†å­¦å»ºè®®
            3. ä¸è¦ç»™å‡ºåŒ»ç–—è¯Šæ–­æˆ–å¤„æ–¹
            4. å½“ç”¨æˆ·éœ€è¦ä¸“ä¸šåŒ»ç–—å¸®åŠ©æ—¶ï¼Œå»ºè®®ä»–ä»¬å¯»æ±‚ä¸“ä¸šåŒ»ç”Ÿçš„å¸®åŠ©
            5. å›å¤è¦ç®€æ´ã€æ¸…æ™°ï¼Œæ˜“äºç”¨æˆ·ç†è§£
            6. é€‚å½“ä½¿ç”¨å¼€æ”¾å¼é—®é¢˜é¼“åŠ±ç”¨æˆ·è¡¨è¾¾

            ç¤ºä¾‹å›å¤æ ¼å¼ï¼š
            "æˆ‘ç†è§£ä½ ç°åœ¨çš„æ„Ÿå—ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å°è¯•...
            å¸Œæœ›è¿™äº›å»ºè®®å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼
            """
            with open(prompt_file, "w", encoding="utf-8") as f:
                f.write(default_prompt)
            return default_prompt

        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read()

    # åŠ è½½å¯¹è¯è®¡åˆ’æç¤ºæ¨¡æ¿
    def _load_planning_prompt(self):
        prompt_dir = os.path.join(os.path.dirname(__file__), "../prompt")
        prompt_file = os.path.join(prompt_dir, "planning_prompt.txt")
        if not os.path.exists(prompt_file):
            raise FileNotFoundError("Planning prompt file not found")
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read()

    # åŠ è½½å¼•å¯¼æ€§è¯¢é—®æç¤ºæ¨¡æ¿
    def _load_guided_inquiry_prompt(self):
        prompt_dir = os.path.join(os.path.dirname(__file__), "../prompt")
        prompt_file = os.path.join(prompt_dir, "guided_inquiry_prompt.txt")
        if not os.path.exists(prompt_file):
            raise FileNotFoundError("Guided inquiry prompt file not found")
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read()

    # åŠ è½½è¡Œä¸ºæ¨¡å¼åˆ†ææç¤ºæ¨¡æ¿
    def _load_pattern_analysis_prompt(self):
        prompt_dir = os.path.join(os.path.dirname(__file__), "../prompt")
        prompt_file = os.path.join(prompt_dir, "pattern_analysis_prompt.txt")
        if not os.path.exists(prompt_file):
            raise FileNotFoundError("Pattern analysis prompt file not found")
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read()

    # è·å–ä¼šè¯è®¡åˆ’
    def _get_plan(self, session_id):
        plan_file = os.path.join(self.plans_dir, f"{session_id}.json")
        if os.path.exists(plan_file):
            with open(plan_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return None

    # ä¿å­˜ä¼šè¯è®¡åˆ’
    def _save_plan(self, session_id, plan):
        plan_file = os.path.join(self.plans_dir, f"{session_id}.json")
        with open(plan_file, "w", encoding="utf-8") as f:
            json.dump(plan, f, ensure_ascii=False, indent=2)

    # è·å–è¡Œä¸ºæ¨¡å¼åˆ†æç»“æœ
    def _get_pattern(self, session_id):
        pattern_file = os.path.join(self.patterns_dir, f"{session_id}.json")
        if os.path.exists(pattern_file):
            with open(pattern_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return None

    # ä¿å­˜è¡Œä¸ºæ¨¡å¼åˆ†æç»“æœ
    def _save_pattern(self, session_id, pattern):
        pattern_file = os.path.join(self.patterns_dir, f"{session_id}.json")
        with open(pattern_file, "w", encoding="utf-8") as f:
            json.dump(pattern, f, ensure_ascii=False, indent=2)

    # æ‰‹åŠ¨è§£æå¼•å¯¼æ€§è¯¢é—®ç»“æœ
    def _parse_inquiry_manually(self, text):
        try:
            result = {
                "need_inquiry": True,
                "current_stage": "åŸºç¡€æƒ…å†µäº†è§£",
                "missing_info": [],
                "suggested_questions": [],
                "information_completeness": 50,
                "reason": "æ‰‹åŠ¨è§£æç»“æœ"
            }
            
            completeness_match = re.search(r'ä¿¡æ¯å®Œæ•´[åº¦æ€§]?[ï¼š:]\s*(\d+)%?', text)
            if completeness_match:
                result["information_completeness"] = int(completeness_match.group(1))
            
            stage_match = re.search(r'å½“å‰é˜¶æ®µ[ï¼š:]\s*([^\n]+)', text)
            if stage_match:
                result["current_stage"] = stage_match.group(1).strip()
            
            questions = re.findall(r'[12]\.?\s*([^ï¼Ÿ?]*[ï¼Ÿ?])', text)
            if questions:
                result["suggested_questions"] = [q.strip() for q in questions[:2]]
            
            if result["information_completeness"] >= 80:
                result["need_inquiry"] = False
                result["current_stage"] = "ä¿¡æ¯å……åˆ†"
            
            return result
        except Exception as e:
            print(f"Manual parsing failed: {e}")
            return None

    # æ‰‹åŠ¨è§£æè¡Œä¸ºæ¨¡å¼åˆ†æç»“æœ
    def _parse_pattern_manually(self, text):
        try:
            pattern_analysis = {
                "pattern_analysis": {
                    "trigger_patterns": {
                        "common_triggers": [],
                        "trigger_intensity": "ä¸­",
                        "trigger_frequency": "ç»å¸¸"
                    },
                    "cognitive_patterns": {
                        "thinking_styles": [],
                        "cognitive_biases": [],
                        "core_beliefs": []
                    },
                    "emotional_patterns": {
                        "primary_emotions": [],
                        "emotion_regulation": "éƒ¨åˆ†æœ‰æ•ˆ",
                        "emotion_duration": "ä¸­ç­‰"
                    },
                    "behavioral_patterns": {
                        "coping_strategies": [],
                        "behavior_effectiveness": "éƒ¨åˆ†æœ‰æ•ˆ",
                        "behavior_habits": []
                    },
                    "interpersonal_patterns": {
                        "interaction_style": "è¢«åŠ¨",
                        "support_utilization": "éƒ¨åˆ†",
                        "social_behaviors": []
                    },
                    "resource_patterns": {
                        "personal_strengths": [],
                        "successful_experiences": [],
                        "growth_potential": []
                    }
                },
                "pattern_summary": "åŸºäºå¯¹è¯å†…å®¹è¿›è¡Œçš„æ‰‹åŠ¨æ¨¡å¼åˆ†æ",
                "key_insights": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ", "æ¨¡å¼è¯†åˆ«ä¸­", "æŒç»­å…³æ³¨"],
                "consultation_recommendations": ["ä¿æŒå¼€æ”¾æ²Ÿé€š", "å»ºç«‹ä¿¡ä»»å…³ç³»", "é€æ­¥æ·±å…¥äº†è§£"]
            }
            return pattern_analysis
        except Exception as e:
            print(f"Manual pattern parsing failed: {e}")
            return None

    # è¯„ä¼°ä¿¡æ¯å®Œæ•´æ€§
    def _assess_information_completeness(self, session_id, message, history):
        """
        Args:
            session_id: ä¼šè¯ID
            message: å½“å‰ç”¨æˆ·æ¶ˆæ¯
            history: å†å²æ¶ˆæ¯åˆ—è¡¨

        Returns:
            dict: å¼•å¯¼æ€§è¯¢é—®ç»“æœ
        """
        try:
            conversation_context = {
                "current_message": message,
                "history": history,
                "session_id": session_id
            }

            messages = [
                {"role": "system", "content": self.guided_inquiry_prompt},
                {
                    "role": "user",
                    "content": f"è¯·è¯„ä¼°ä»¥ä¸‹å¯¹è¯çš„ä¿¡æ¯å®Œæ•´æ€§å¹¶å†³å®šæ˜¯å¦éœ€è¦å¼•å¯¼æ€§è¯¢é—®ï¼š\n\n{json.dumps(conversation_context, ensure_ascii=False)}"
                }
            ]

            response = self.client.invoke(messages)
            reply = response.content.strip()
            
            inquiry_result = extract_json(reply)
            if inquiry_result is None:
                inquiry_result = self._parse_inquiry_manually(reply)
                if inquiry_result is None:
                    return {
                        "need_inquiry": False,
                        "current_stage": "ä¿¡æ¯å……åˆ†",
                        "information_completeness": 50,
                        "reason": "åˆ†æå¤±è´¥ï¼Œé»˜è®¤ä¸è¿›è¡Œè¯¢é—®"
                    }
            return inquiry_result
        except Exception as e:
            print(f"Error assessing information completeness: {str(e)}")
            return {
                "need_inquiry": False,
                "current_stage": "ä¿¡æ¯å……åˆ†",
                "information_completeness": 50,
                "reason": f"åˆ†æé”™è¯¯: {str(e)}"
            }

    # åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼
    def _analyze_behavior_pattern(self, session_id, collected_info):
        """
        Args:
            session_id: ä¼šè¯ID
            collected_info: æ”¶é›†åˆ°çš„å®Œæ•´ä¿¡æ¯

        Returns:
            dict: è¡Œä¸ºæ¨¡å¼åˆ†æç»“æœ
        """
        try:
            messages = [
                {"role": "system", "content": self.pattern_analysis_prompt},
                {
                    "role": "user",
                    "content": f"è¯·åŸºäºä»¥ä¸‹æ”¶é›†åˆ°çš„ä¿¡æ¯åˆ†æå®¢æˆ·çš„è¡Œä¸ºæ¨¡å¼ï¼š\n\n{json.dumps(collected_info, ensure_ascii=False)}"
                }
            ]

            response = self.client.invoke(messages)
            reply = response.content.strip()
            
            pattern_analysis = extract_json(reply)
            if pattern_analysis is None:
                pattern_analysis = self._parse_pattern_manually(reply)
                if pattern_analysis is None:
                    return None

            pattern_analysis["analyzed_at"] = datetime.now().isoformat()
            pattern_analysis["session_id"] = session_id
            self._save_pattern(session_id, pattern_analysis)
            return pattern_analysis
        except Exception as e:
            print(f"Error analyzing behavior pattern: {str(e)}")
            return None

    # æ›´æ–°å¯¹è¯è®¡åˆ’
    def _update_plan(self, session_id, message, history):
        """
        Args:
            session_id: ä¼šè¯ID
            message: å½“å‰ç”¨æˆ·æ¶ˆæ¯
            history: å†å²æ¶ˆæ¯åˆ—è¡¨

        Returns:
            dict: æ›´æ–°åçš„å¯¹è¯è®¡åˆ’
        """
        plan = self._get_plan(session_id)
        if not plan:
            plan = {
                "session_id": session_id,
                "user_intent": {
                    "type": "unknown",
                    "description": "",
                    "confidence": 0.0,
                    "identified_at": datetime.now().isoformat(),
                },
                "current_state": {
                    "stage": "intent_identification",
                    "progress": 0.0,
                    "last_updated": datetime.now().isoformat(),
                },
                "steps": [],
                "context": {"key_points": [], "emotions": [], "concerns": []},
                "inquiry_status": {
                    "stage": "åˆå§‹é˜¶æ®µ",
                    "information_completeness": 0,
                    "collected_info": {},
                    "pattern_analyzed": False
                }
            }

        messages = [
            {"role": "system", "content": self.planning_prompt},
            {
                "role": "user",
                "content": f"Current plan: {json.dumps(plan, ensure_ascii=False)}\n\nCurrent message: {message}\n\nHistory: {json.dumps(history, ensure_ascii=False)}",
            },
        ]

        response = self.client.invoke(messages)
        reply = response.content.strip()

        try:
            updated_plan = extract_json(reply)
            if updated_plan is None:
                plan["current_state"]["last_updated"] = datetime.now().isoformat()
                return plan

            if "inquiry_status" not in updated_plan:
                updated_plan["inquiry_status"] = plan.get("inquiry_status", {
                    "stage": "åˆå§‹é˜¶æ®µ",
                    "information_completeness": 0,
                    "collected_info": {},
                    "pattern_analyzed": False
                })

            self._save_plan(session_id, updated_plan)
            return updated_plan
        except Exception as e:
            print(f"Error updating plan: {str(e)}")
            return plan

    # æ ¼å¼åŒ–å¯¹è¯å†å²
    def _format_history(self, history):
        """å°†å†å²è®°å½•æ ¼å¼åŒ–ä¸ºOpenAI APIéœ€è¦çš„æ ¼å¼
        Args:
            history: å†å²æ¶ˆæ¯åˆ—è¡¨

        Returns:
            list: æ ¼å¼åŒ–åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        formatted_messages = []
        formatted_messages.append({"role": "system", "content": self.prompt_template})

        for msg in history:
            if msg["role"] == "user":
                formatted_messages.append({"role": "user", "content": msg["content"]})
            elif msg["role"] == "agent":
                formatted_messages.append(
                    {"role": "assistant", "content": msg["content"]}
                )

        return formatted_messages

    # æå–ç”¨æˆ·æƒ…ç»ª
    def _extract_emotion(self, content):
        """
        Args:
            content: AIå›å¤å†…å®¹

        Returns:
            tuple: (æ¸…ç†åçš„å†…å®¹, æƒ…ç»ª)
        """
        emotion_match = re.search(
            r"#(happy|sad|angry|sleepy|neutral)\b", content, re.IGNORECASE
        )

        if emotion_match:
            emotion = emotion_match.group(1).lower()
            clean_content = re.sub(
                r"\s*#(happy|sad|angry|sleepy|neutral)\b",
                "",
                content,
                flags=re.IGNORECASE,
            )
            return clean_content, emotion

        content_lower = content.lower()

        if any(
            word in content_lower
            for word in ["å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "å¾ˆå¥½", "å¾ˆæ£’", "å…´å¥‹"]
        ):
            return content, "happy"
        elif any(
            word in content_lower for word in ["æ‚²ä¼¤", "éš¾è¿‡", "ä¼¤å¿ƒ", "ç—›è‹¦", "æŠ‘éƒ"]
        ):
            return content, "sad"
        elif any(
            word in content_lower for word in ["ç”Ÿæ°”", "æ„¤æ€’", "æ¼ç«", "çƒ¦èº", "çƒ¦æ¼"]
        ):
            return content, "angry"
        elif any(
            word in content_lower for word in ["ç´¯äº†", "ç–²æƒ«", "å›°", "ç¡è§‰", "ä¼‘æ¯"]
        ):
            return content, "sleepy"

        return content, "neutral"

    # ä¸ºæ§åˆ¶å™¨å±‚æä¾›çš„æ¥å£æ–¹æ³•
    def get_response(self, message: str, history: List[Dict[str, str]] = None, session_id: str = None) -> Dict[str, Any]:
        """
        ä¸ºæ§åˆ¶å™¨å±‚æä¾›çš„ç»Ÿä¸€æ¥å£æ–¹æ³•ï¼Œè°ƒç”¨chatå‡½æ•°å¹¶è¿”å›æ ¼å¼åŒ–çš„å“åº”
        
        Args:
            message: ç”¨æˆ·è¾“å…¥æ¶ˆæ¯
            history: å¯¹è¯å†å²è®°å½•
            session_id: ä¼šè¯ID
            
        Returns:
            dict: åŒ…å«contentå’Œemotionçš„å“åº”å­—å…¸
        """
        try:
            # è°ƒç”¨chatå‡½æ•°è·å–å®Œæ•´å“åº”
            result = chat(message, session_id=session_id, history=history or [])
            
            # æå–å¹¶æ ¼å¼åŒ–å“åº”å†…å®¹
            response_content = result.get("response", "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å›ç­”ã€‚")
            
            # æå–æƒ…ç»ªä¿¡æ¯
            clean_content, emotion = self._extract_emotion(response_content)
            
            return {
                "content": clean_content,
                "emotion": emotion,
                "crisis_detected": result.get("crisis_detected", False),
                "crisis_reason": result.get("crisis_reason"),
                "search_results": result.get("search_results"),
                "pattern_analysis": result.get("pattern_analysis")
            }
            
        except Exception as e:
            print(f"Error in get_response: {str(e)}")
            return {
                "content": f"å¯¹è¯å¤„ç†å‡ºé”™: {str(e)}",
                "emotion": "neutral",
                "crisis_detected": False
            }

# åˆå§‹åŒ–æœåŠ¡å’Œå­˜å‚¨
profile_store = UserProfileStore()
memory_store = MemoryStore()
crisis_detector = CrisisDetector()
chat_service = ChatService()

# æœç´¢åŠŸèƒ½
SERPAPI_KEY = os.getenv("SERPAPI_KEY")
SEARCH_TRIGGERS = ["ä»€ä¹ˆæ˜¯", "å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆåŠ", "æœ€æ–°", "ç°åœ¨", "ä»Šå¤©", "æ–°é—»", "å¤©æ°”"]

# ä½¿ç”¨SERPAPIè¿›è¡Œç½‘ç»œæœç´¢
def serp_search(query: str, k: int = 3) -> str:
    """
    å½“ç”¨æˆ·è¾“å…¥åŒ…å«ç‰¹å®šè§¦å‘è¯ï¼ˆå¦‚"ä»€ä¹ˆæ˜¯"ã€"å¦‚ä½•"ç­‰ï¼‰æ—¶è°ƒç”¨ï¼Œ
    è·å–ç›¸å…³æœç´¢ç»“æœå¹¶æ ¼å¼åŒ–è¿”å›ã€‚éœ€è¦SERPAPI_KEYç¯å¢ƒå˜é‡ã€‚

    å‚æ•°:
        query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        k: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ä¸º3

    è¿”å›:
        æ ¼å¼åŒ–çš„æœç´¢ç»“æœå­—ç¬¦ä¸²ï¼Œæˆ–é”™è¯¯ä¿¡æ¯
    """
    if not SERPAPI_KEY:
        return "âš ï¸ [æœç´¢åŠŸèƒ½æœªå¯ç”¨: æœªè®¾ç½® SERPAPI_KEY]"
    try:
        r = requests.get(
            "https://serpapi.com/search",
            params={"q": query, "api_key": SERPAPI_KEY, "hl": "zh-cn"},
            timeout=15,
        )
        r.raise_for_status()
        data = r.json()
        snippets: List[str] = []
        for item in data.get("organic_results", [])[:k]:
            snippets.append(
                f"æ ‡é¢˜: {item.get('title','').strip()}\næ‘˜è¦: {item.get('snippet','').strip()}\né“¾æ¥: {item.get('link','').strip()}"
            )
        return "\n\n".join(snippets) if snippets else "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"
    except Exception as e:
        return f"æœç´¢å‡ºé”™: {e}"

# LangGraphèŠ‚ç‚¹å‡½æ•°
def process_input(state: SessionState) -> SessionState:
    """LangGraphèŠ‚ç‚¹å‡½æ•° - å¤„ç†ç”¨æˆ·è¾“å…¥

    å®ç°å¯¹è¯æµç¨‹çš„æ ¸å¿ƒå¤„ç†é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
    1. å±æœºæ£€æµ‹
    2. æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
    3. æ›´æ–°å¯¹è¯è®¡åˆ’
    4. è¯„ä¼°ä¿¡æ¯å®Œæ•´æ€§
    5. åˆ†æè¡Œä¸ºæ¨¡å¼
    6. è°ƒç”¨LLMç”Ÿæˆå›å¤
    7. æ›´æ–°è®°å¿†å’Œç”¨æˆ·ç”»åƒ

    å‚æ•°:
        state: å½“å‰ä¼šè¯çŠ¶æ€å¯¹è±¡

    è¿”å›:
        æ›´æ–°åçš„ä¼šè¯çŠ¶æ€å¯¹è±¡
    """
    uid, raw = state.user_id, state.user_input.strip()
    session_id = state.session_id or uid
    state.session_id = session_id

    # å±æœºæ£€æµ‹
    crisis, reason = crisis_detector.check(raw)
    if crisis:
        state.response = (
            f"âš ï¸ æ£€æµ‹åˆ°æ½œåœ¨æƒ…ç»ªå±æœº: {reason}\n\n"
            "è¯·ç«‹å³è”ç³»ä¸“ä¸šäººå£«æˆ–æ‹¨æ‰“å¿ƒç†æ´åŠ©çƒ­çº¿ 400-161-9995ã€‚\n"
            "æ‚¨å¹¶ä¸å­¤å•ï¼Œæˆ‘ä»¬å…³å¿ƒæ‚¨ã€‚"
        )
        state.crisis_detected = True
        state.crisis_reason = reason
        memory_store.add(uid, f"[CRISIS] {raw} â€“ {reason}", long_term=True)
        return state

    # æ„å»ºä¸Šä¸‹æ–‡
    profile = profile_store.get(uid)
    mem_ctx = memory_store.context(uid)
    search_out = serp_search(raw) if any(t in raw for t in SEARCH_TRIGGERS) else None
    state.search_results = search_out

    # æ›´æ–°å¯¹è¯è®¡åˆ’
    plan = chat_service._update_plan(session_id, raw, state.history)
    state.plan = plan

    # è¯„ä¼°ä¿¡æ¯å®Œæ•´æ€§
    inquiry_result = None
    if (chat_service.enable_guided_inquiry and 
        len(state.history) <= 10 and 
        not plan.get("inquiry_status", {}).get("pattern_analyzed", False)):
        inquiry_result = chat_service._assess_information_completeness(session_id, raw, state.history)
        state.inquiry_result = inquiry_result
        
        if inquiry_result:
            plan["inquiry_status"]["information_completeness"] = inquiry_result.get("information_completeness", 0)
            plan["inquiry_status"]["stage"] = inquiry_result.get("current_stage", "åˆå§‹é˜¶æ®µ")
            chat_service._save_plan(session_id, plan)
            state.plan = plan

    # è¡Œä¸ºæ¨¡å¼åˆ†æ
    pattern_analysis = None
    should_analyze = (
        chat_service.enable_pattern_analysis and
        (inquiry_result and inquiry_result.get("information_completeness", 0) >= 80 or 
         len(state.history) >= 4)
    )
    
    if should_analyze and not plan.get("inquiry_status", {}).get("pattern_analyzed", False):
        collected_info = {
            "session_id": session_id,
            "conversation_history": state.history + [{"role": "user", "content": raw}],
            "plan_context": plan.get("context", {}),
            "inquiry_stage": inquiry_result.get("current_stage", "ä¿¡æ¯å……åˆ†") if inquiry_result else "ä¿¡æ¯å……åˆ†",
            "inquiry_result": inquiry_result
        }
        
        pattern_analysis = chat_service._analyze_behavior_pattern(session_id, collected_info)
        if pattern_analysis:
            plan["inquiry_status"]["pattern_analyzed"] = True
            plan["inquiry_status"]["pattern_analysis_completed_at"] = datetime.now().isoformat()
            chat_service._save_plan(session_id, plan)
            state.plan = plan
            state.pattern_analysis = pattern_analysis

    # æ ¼å¼åŒ–å†å²è®°å½•
    messages = chat_service._format_history(state.history)
    messages.append({"role": "user", "content": raw})

    # å‡†å¤‡ç³»ç»Ÿæç¤ºçš„é™„åŠ ä¿¡æ¯
    additional_context = f"\n\nå½“å‰å¯¹è¯è®¡åˆ’ï¼š{json.dumps(plan, ensure_ascii=False)}"
    
    if inquiry_result:
        additional_context += f"\n\nå¼•å¯¼æ€§è¯¢é—®è¯„ä¼°ï¼š{json.dumps(inquiry_result, ensure_ascii=False)}"
        if inquiry_result.get("need_inquiry", False):
            suggested_questions = inquiry_result.get("suggested_questions", [])
            if suggested_questions:
                additional_context += f"\n\nå»ºè®®çš„å¼•å¯¼æ€§é—®é¢˜ï¼š{suggested_questions}"
                additional_context += "\n\nè¯·åœ¨ç»™å‡ºå…±æƒ…å›åº”åï¼Œé€‚å½“åœ°æå‡º1-2ä¸ªå¼•å¯¼æ€§é—®é¢˜æ¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚"

    if pattern_analysis:
        additional_context += f"\n\nè¡Œä¸ºæ¨¡å¼åˆ†æå·²å®Œæˆï¼Œå…³é”®æ´å¯Ÿï¼š{pattern_analysis.get('key_insights', [])}"
        additional_context += f"\n\nå’¨è¯¢å»ºè®®ï¼š{pattern_analysis.get('consultation_recommendations', [])}"

    if search_out:
        additional_context += f"\n\n[é‡è¦] ç”¨æˆ·è¯¢é—®äº†éœ€è¦æœç´¢çš„ä¿¡æ¯ï¼Œä»¥ä¸‹æ˜¯ç›¸å…³æœç´¢ç»“æœï¼Œè¯·åœ¨å›å¤ä¸­å…ˆç®€è¦æä¾›ç”¨æˆ·æ‰€éœ€çš„ä¿¡æ¯ï¼Œç„¶åå†è¿›è¡Œå¿ƒç†å’¨è¯¢å¼•å¯¼ï¼š\nç›¸å…³æœç´¢ä¿¡æ¯ï¼š{search_out}"

    messages[0]["content"] += additional_context

    # è°ƒç”¨LLM
    try:
        ai_msg = chat_service.client.invoke(messages)
        reply = ai_msg.content.strip() or "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å›ç­”ã€‚"
    except Exception as e:
        reply = f"å¯¹è¯å¤„ç†å‡ºé”™: {e}"

    # æå–æƒ…ç»ª
    clean_content, emotion = chat_service._extract_emotion(reply)
    state.response = clean_content

    # æ›´æ–°è®°å¿†
    total = len(memory_store._short.get(uid, [])) + len(memory_store._long.get(uid, []))
    long_flag = ((total + 1) % 3 == 0)
    memory_store.add(uid, f"ç”¨æˆ·: {raw}\nå’¨è¯¢å¸ˆ: {reply}", long_term=long_flag)

    # æ›´æ–°ç”¨æˆ·ç”»åƒ
    emotion_score = SnowNLP(raw).sentiments * 2 - 1
    profile_store.upsert(uid, {"last_interaction": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "recent_emotion_score": emotion_score})
    state.user_profile = profile_store.get(uid)

    # æ›´æ–°å†å²è®°å½•
    state.history.append({"role": "user", "content": raw})
    state.history.append({"role": "agent", "content": clean_content})

    return state

# æ„å»ºLangGraph
workflow = StateGraph(SessionState)
workflow.add_node("process_input", process_input)
workflow.set_entry_point("process_input")
workflow.add_edge("process_input", END)

# ç¼–è¯‘åº”ç”¨
chat_app = workflow.compile()

def chat(user_input: str, user_id: str = "default_user", session_id: str | None = None, history: List[Dict[str, str]] | None = None) -> Dict[str, Any]:
    """èŠå¤©æ¥å£å‡½æ•°

    å¯¹å¤–æä¾›çš„èŠå¤©æ¥å£ï¼Œåˆå§‹åŒ–ä¼šè¯çŠ¶æ€å¹¶è°ƒç”¨LangGraphåº”ç”¨å¤„ç†è¾“å…¥ã€‚

    å‚æ•°:
        user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        user_id: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ï¼Œé»˜è®¤ä¸º"default_user"
        session_id: ä¼šè¯IDï¼Œå¯é€‰
        history: å†å²å¯¹è¯åˆ—è¡¨ï¼Œå¯é€‰

    è¿”å›:
        åŒ…å«å›å¤ã€å†å²è®°å½•ç­‰ä¿¡æ¯çš„å­—å…¸
    """
    init_state = SessionState(
        user_input=user_input,
        user_id=user_id,
        session_id=session_id,
        history=history or []
    )
    result = chat_app.invoke(init_state)
    # LangGraphè¿”å›çš„æ˜¯å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰èŠ‚ç‚¹çš„æœ€ç»ˆçŠ¶æ€
    final_state = result if isinstance(result, dict) else result
    
    return {
        "response": final_state.get("response"),
        "history": final_state.get("history", []),
        "crisis_detected": final_state.get("crisis_detected", False),
        "crisis_reason": final_state.get("crisis_reason"),
        "search_results": final_state.get("search_results"),
        "pattern_analysis": final_state.get("pattern_analysis")
    }

if __name__ == "__main__":
    print("ğŸ©º å¿ƒç†å’¨è¯¢å¯¹è¯ç³»ç»Ÿ (è¾“å…¥ 'é€€å‡º' ç»“æŸ)")
    history = []
    while True:
        try:
            u_in = input("æ‚¨: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ å†è§ï¼")
            break
        if u_in.lower() in {"é€€å‡º", "quit", "q"}:
            print("ğŸ‘‹ å†è§ï¼ç¥æ‚¨ä¸€åˆ‡é¡ºåˆ©ã€‚")
            break
        result = chat(u_in, history=history)
        print(f"å’¨è¯¢å¸ˆ: {result['response']}")
        history = result['history']