# Server configuration
FLASK_ENV=development
PORT=5858
HOST=0.0.0.0

# OpenAI API key (required)
# The OPENAI_API_KEY is temporary for demonstration purposes, may not work in the future.
OPENAI_API_KEY="3d66eb99-57a4-480c-b556-ff12bf9db951"
BASE_URL="https://api.sambanova.ai/v1"
# Model configuration
# MODEL_NAME="DeepSeek-V3-0324"
MODEL_NAME="Meta-Llama-3.1-8B-Instruct"
MAX_TOKENS=1000
TEMPERATURE=0.1

# 是否启用引导式查询
# 是否启用模式分析
# 这些功能可以帮助用户更好地理解和使用模型，但可能会增加响应时间和复杂性
# 如果不需要这些功能，可以将其设置为 False
ENABLE_GUIDED_INQUIRY=False
ENABLE_PATTERN_ANALYSIS=False

# 对话模型配置
CHAT_API_KEY="3d66eb99-57a4-480c-b556-ff12bf9db951"
CHAT_MODEL_NAME=Meta-Llama-3.1-8B-Instruct
CHAT_BASE_URL=https://api.sambanova.ai/v1

# 事件提取模型配置
EVENT_API_KEY="d3e47d44-18a3-497d-816e-bd4272b77f43"
EVENT_MODEL_NAME=DeepSeek-V3-0324
EVENT_BASE_URL=https://api.sambanova.ai/v1

# The SERPAPI_KEY is temporary for demonstration purposes, may not work in the future.
SERPAPI_KEY="54ebbdeb4413ea6e4213253928f58ba18d4b854ba256c2c1b6965919a80ae22d"

# RAG系统配置
ENABLE_RAG=true
RAG_DEVICE=auto
RAG_FORCE_CPU=false
RAG_CHUNK_SIZE=512
RAG_CHUNK_OVERLAP=50
RAG_BATCH_SIZE=8

# MPS内存管理配置（仅用于Apple Silicon Mac）
# PYTORCH_MPS_HIGH_WATERMARK_RATIO控制MPS内存池的高水位线比率
# 0.0 = 禁用内存上限（可能导致系统不稳定，但避免out of memory错误）
# 0.7 = 默认值（推荐用于生产环境）
PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0
PYTORCH_MPS_ALLOCATOR_POLICY=garbage_collection

# Tokenizers配置（避免并行处理警告）
TOKENIZERS_PARALLELISM=false

# 日志配置
ENABLE_CHAT_LOGGING=true
ENABLE_EMOTION_LOGGING=true
ENABLE_DETAILED_LOGGING=true